{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision import datasets, transforms\n",
    "from torchinfo import summary\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from data_setup import create_dataloaders\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from utils import create_writer,save_model ,CLAHETransform\n",
    "import model\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from model import *\n",
    "import engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Helper functions\n",
    "\n",
    "def simple_moving_average(data, window_size=20):\n",
    "    \"\"\"Calculate the Simple Moving Average (SMA) of a list.\"\"\"\n",
    "    sma = []\n",
    "    for i in range(len(data)):\n",
    "        # Calculate the start of the window\n",
    "        start = max(0, i - window_size + 1)\n",
    "        # Calculate the average for the current window\n",
    "        average = sum(data[start:i + 1]) / (i - start + 1)\n",
    "        sma.append(average)\n",
    "    return sma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"datasets/train\"\n",
    "val_dir = \"datasets/val\"\n",
    "\n",
    "# Setup target device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# Create auto-transforms\n",
    "transforms = torchvision.models.VGG19_Weights.DEFAULT.transforms() \n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader, test_dataloader, val_dataloader, class_names = create_dataloaders(\n",
    "        train_dir=train_dir,\n",
    "        val_dir=val_dir,\n",
    "        transform=transforms,\n",
    "        batch_size=int(os.getenv('BATCH_SIZE')),\n",
    "    )\n",
    "# Create vgg model\n",
    "model_vgg19 = model.create_vgg19(device=device,class_names=class_names).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)(i) Dataset Splitting and Composition\n",
    "The dataset was divided into four distinct sets: **training**, **testing**, **validation**, and **production datasets**.\n",
    "\n",
    "- **Training set**: This set was used to train the model and adjust the parameters during the learning process.\n",
    "- **Testing set**: This set was used to evaluate the model's performance after training and to measure generalization.\n",
    "- **Validation set**: This set was employed during training to monitor performance and facilitate early stopping, helping to prevent overfitting.\n",
    "- **Production dataset**: This set consists of real-world data that the model encounters in a production environment, where it makes predictions without labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the size of the training dataset\n",
    "train_size = len(train_dataloader.dataset)\n",
    "\n",
    "# Get the size of the validation dataset\n",
    "val_size = len(val_dataloader.dataset)\n",
    "\n",
    "# Get the size of the test dataset (if applicable)\n",
    "test_size = len(test_dataloader.dataset)\n",
    "\n",
    "# Print the dataset sizes\n",
    "print(f\"Training dataset size: {train_size}\")\n",
    "print(f\"Test dataset size: {test_size}\")\n",
    "print(f\"Validation dataset size: {val_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)(ii) [INCOMPLETE] Data Pre-processing and Augmentation\n",
    "The data preprocessing pipeline included transformations similar to those used in training the VGG model on the ImageNet dataset. These transformations included standard resizing, normalization, and mean subtraction to align with the original VGG training setup.\n",
    "\n",
    "Various image augmentation techniques were also explored to enhance model generalization, such as:\n",
    "- Horizontal flipping\n",
    "- Color jittering\n",
    "- Rotation adjustments\n",
    "- CLAHE Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG19 Default Transforms\n",
    "vgg_transform = torchvision.models.VGG19_Weights.DEFAULT.transforms()\n",
    "vgg_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLAHE Histogram Equalisation\n",
    "\n",
    "image = cv2.imread('datasets/train/cat/cat.841.jpg') # OpenCV uses BGR instead of RGB\n",
    "\n",
    "lab_image = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "\n",
    "# Split the LAB image to L, A, and B components\n",
    "L, A, B = cv2.split(lab_image)\n",
    "\n",
    "# Apply CLAHE to the L channel\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "L_clahe = clahe.apply(L)\n",
    "\n",
    "# Merge the CLAHE L' channel back with A and B channels\n",
    "lab_clahe_image = cv2.merge((L_clahe, A, B))\n",
    "\n",
    "# Convert L'AB back to RGB\n",
    "rgb_clahe_image = cv2.cvtColor(lab_clahe_image, cv2.COLOR_LAB2RGB)\n",
    "\n",
    "rgb_clahe_image = rgb_clahe_image.transpose(2,1,0)\n",
    "rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "rgb_image = rgb_image.transpose(2,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAHE Histogram Equalisation Comparison\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# RGB histogram\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(rgb_image[0,:,:].ravel(), bins=256, color='red', alpha=0.7)\n",
    "plt.title(\"RGB Channel\")\n",
    "plt.xlim([0, 256])\n",
    "\n",
    "# RGB CLAHE histogram\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(rgb_clahe_image[0,:,:].ravel(), bins=256, color='green', alpha=0.7)\n",
    "plt.title(\"RGB LAB CLAHE Channel\")\n",
    "plt.xlim([0, 256])\n",
    "\n",
    "# Display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAHE Histogram Equalisation Example\n",
    "plt.figure(figsize=(10, 5))  # Adjust the figure size as needed\n",
    "\n",
    "# Plot the first image\n",
    "plt.subplot(1, 2, 1)  # 1 row, 2 columns, first subplot\n",
    "plt.imshow(np.rot90(rgb_image.transpose(1,2,0), k=-1))\n",
    "plt.title(\"RGB\")\n",
    "plt.axis('off')  # Hide the axis\n",
    "\n",
    "# Plot the second image\n",
    "plt.subplot(1, 2, 2)  # 1 row, 2 columns, second subplot\n",
    "plt.imshow(np.rot90(rgb_clahe_image.transpose(1,2,0), k=-1))\n",
    "plt.title(\"RGB LAB CLAHE\")\n",
    "plt.axis('off')  # Hide the axis\n",
    "\n",
    "# Display the images\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)(i) Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model=model_vgg19, \n",
    "        input_size=(32, 3, 224, 224),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)(ii) Training Strategy\n",
    "\n",
    "1. **Forward Pass**  \n",
    "   The model processes the input data through its layers to produce predictions.\n",
    "\n",
    "2. **Calculate Loss**  \n",
    "   The model’s predictions are compared to the ground truth labels to calculate the error using a loss function.\n",
    "\n",
    "3. **Zero Gradients**  \n",
    "   Before backpropagation, the accumulated gradients from previous steps are cleared to ensure accurate gradient computation for the current step.\n",
    "\n",
    "4. **Backpropagation**  \n",
    "   The gradient of the loss with respect to each trainable parameter is computed. This is done using backpropagation to propagate errors back through the network.\n",
    "\n",
    "5. **Update Weights**  \n",
    "   The optimizer updates the model's parameters using the gradients to minimize the loss function and improve predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)(i) Epoch Selection\n",
    "\n",
    "Selecting the optimal number of epochs is crucial in training machine learning models to prevent overfitting and ensure good generalization on unseen data. Early stopping is an effective strategy that involves monitoring the model’s performance on a validation set and halting training when performance stops improving.\n",
    "\n",
    "In this project, we utilize the `EarlyStopper` class for epoch selection with the following key features:\n",
    "\n",
    "- **Patience:** Defines the number of epochs to wait for an improvement in validation loss before stopping. In our implementation, `patience=3` means training halts if validation loss does not improve for three consecutive epochs.\n",
    "\n",
    "- **Minimum Delta:** Specifies the minimum change in validation loss that qualifies as an improvement. Here, `min_delta=10` indicates that a decrease in validation loss must exceed 10 to reset the patience counter.\n",
    "\n",
    "Using early stopping optimizes the training process, reduces training time, and enhances the model's generalization ability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c)(ii) Learning Rate Selection \n",
    "\n",
    "#### Naive Approach\n",
    "The naive approach involves starting with a relatively large learning rate, such as **0.1**, and then progressively testing smaller values in an exponential decay manner. This can include values like **0.01**, **0.001**, etc. While this method can yield decent results, it may not always effectively identify the optimal learning rate for the model.\n",
    "\n",
    "#### Proposed Approach\n",
    "To enhance the learning rate selection process, we propose a more dynamic strategy:\n",
    "\n",
    "1. **Initial Learning Rate**: Begin with a low learning rate, such as **0.0001**.\n",
    "2. **Exponential Increase**: Gradually increase the learning rate exponentially with each training batch. This allows the model to quickly adapt to the optimal rate for convergence.\n",
    "3. **Monitoring Progress**: For each batch, record both the learning rate and the corresponding training loss.\n",
    "4. **Identifying Optimal Point**: Analyze the recorded data to identify the point at which the training loss exhibits the fastest decrease. This is determined by finding the steepest negative derivative of the loss concerning the learning rate.\n",
    "5. **Smoothing Noisy Curves**: If the resulting curve is excessively noisy, apply a simple moving average (SMA) to smooth the data, allowing for clearer insights into the loss trends.\n",
    "\n",
    "Reference: [1506.01186] Cyclical Learning Rates for Training Neural Networks \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyclical Learning Rates Implementation\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model_vgg19 = model.create_vgg19(device=device,class_names=class_names).to(device)\n",
    "\n",
    "# Initializing parameters\n",
    "initial_lr = 1e-5  # Lower initial learning rate\n",
    "max_lr = 1e-2  # Lower maximum learning rate\n",
    "num_batches = len(train_dataloader)  # Number of batches in the dataloader\n",
    "\n",
    "scaling_factor = (max_lr / initial_lr) ** (1 / num_batches)  # Calculate scaling factor for exponential increase\n",
    "\n",
    "# Initialize the optimizer with the initial learning rate\n",
    "optimizer = torch.optim.Adam(model_vgg19.parameters(), lr=initial_lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Lists to store learning rates and losses\n",
    "learning_rates = []\n",
    "losses = []\n",
    "\n",
    "model_vgg19.train()  # Set the model to training mode\n",
    "epoch_loss = 0.0  # Initialize cumulative loss for the epoch\n",
    "\n",
    "# Iterate through the dataloader\n",
    "for X, y in train_dataloader:\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    # Forward pass\n",
    "    outputs = model_vgg19(X)\n",
    "    loss = loss_fn(outputs, y)\n",
    "\n",
    "    # Backward pass and optimization step\n",
    "    optimizer.zero_grad()  # Reset gradients\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()  # Update parameters\n",
    "\n",
    "    # Record the loss for this batch\n",
    "    epoch_loss += loss.item()\n",
    "\n",
    "    # Record the current learning rate\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    learning_rates.append(current_lr)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    # Update learning rate exponentially\n",
    "    new_lr = current_lr * scaling_factor\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = new_lr\n",
    "\n",
    "    # Average loss for the epoch\n",
    "avg_loss = epoch_loss / len(train_dataloader)\n",
    "\n",
    "\n",
    "# Plotting learning rate against training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(learning_rates, losses, marker='o')\n",
    "plt.title('Learning Rate vs Training Loss')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Training Loss')\n",
    "plt.xscale('log') \n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots for Batch - SMA and Learning Rate - SMA Loss\n",
    "\n",
    "# Choose a window size\n",
    "window_size = 20\n",
    "\n",
    "# Calculate SMA\n",
    "sma_learning_rates = simple_moving_average(learning_rates[:200], window_size)\n",
    "sma_losses = simple_moving_average(losses[:200], window_size)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(learning_rates, label='Learning Rates', linestyle='-')\n",
    "plt.title('Learning Rates')\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.legend()\n",
    "\n",
    "# Subplot 2: Smoothed Losses vs Learning Rates\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(sma_learning_rates, sma_losses, linestyle='-', label='SMA Losses')\n",
    "plt.title('SMA Losses vs Learning Rates')\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('SMA Loss')\n",
    "plt.xscale('log')  # Use logarithmic scale for better visualization\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "# Show the plot\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the derivative of losses\n",
    "loss_derivative = np.gradient(sma_losses)\n",
    "sma_loss_derivative = simple_moving_average(loss_derivative, window_size)\n",
    "\n",
    "# Plot the derivative of losses against smoothed learning rates\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(sma_learning_rates[:200], sma_loss_derivative[:200], linestyle='-')\n",
    "plt.title('Derivative of Losses vs SMA Learning Rates')\n",
    "plt.xlabel('SMA Learning Rates')\n",
    "plt.ylabel('Derivative of Losses')\n",
    "plt.xscale('log') \n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Case 1: VGG Default Transform\n",
    "transform_case_1 = torchvision.models.VGG19_Weights.DEFAULT.transforms()\n",
    "\n",
    "# Case 2: CLAHE\n",
    "transform_case_2 = transforms.Compose([\n",
    "    CLAHETransform(clip_limit=2.0, tile_grid_size=(8, 8)),  # Apply CLAHE\n",
    "    transforms.Resize((256, 256), # Resize to 256x256\n",
    "    interpolation=InterpolationMode.BICUBIC),  \n",
    "    transforms.CenterCrop(224),  # Crop to 224x224\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "# Case 3: Rotation + Horizontal Flip\n",
    "transform_case_3 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
    "\n",
    "])\n",
    "# Case 4: CLAHE + Rotation + Horizontal Flip\n",
    "transform_case_4 = transforms.Compose([\n",
    "    CLAHETransform(clip_limit=2.0, tile_grid_size=(8, 8)),  # Apply CLAHE\n",
    "    transforms.Resize((256, 256), # Resize to 256x256\n",
    "    interpolation=InterpolationMode.BICUBIC),  \n",
    "    transforms.CenterCrop(224),  # Crop to 224x224\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders_helper(transformation):\n",
    "    return create_dataloaders(train_dir=train_dir,val_dir=val_dir,transform=transformation,\n",
    "                              batch_size=int(os.getenv('BATCH_SIZE')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dataloaders = {\n",
    "                        \"Default Transform\": create_dataloaders_helper(transform_case_1),\n",
    "                        \"CLAHE Transform\": create_dataloaders_helper(transform_case_2),\n",
    "                        \"Rotation + Horizontal Flip Transform\": create_dataloaders_helper(transform_case_3),\n",
    "                        \"CLAHE + Rotation + Horizontal Flip Transform\": create_dataloaders_helper(transform_case_4),\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Set the random seeds\n",
    "torch.manual_seed(42)\n",
    "\n",
    "models = [\"vgg11\",\"vgg16\",\"vgg19\"]\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "num_epochs = [10]\n",
    "# 2. Keep track of experiment numbers\n",
    "experiment_number = 0\n",
    "\n",
    "# 3. Loop through each DataLoader\n",
    "for dataloader_name, dataloaders in experiment_dataloaders.items():\n",
    "    class_names = dataloaders[-1]\n",
    "    # 4. Loop through each number of epochs\n",
    "    for epochs in num_epochs: \n",
    "\n",
    "        # 5. Loop through each model name and create a new model based on the name\n",
    "        for model_name in models:\n",
    "\n",
    "            # 6. Create information print outs\n",
    "            experiment_number += 1\n",
    "            print(f\"[INFO] Experiment number: {experiment_number}\")\n",
    "            print(f\"[INFO] Model: {model_name}\")\n",
    "            print(f\"[INFO] DataLoader: {dataloader_name}\")\n",
    "            print(f\"[INFO] Number of epochs: {epochs}\")  \n",
    "\n",
    "            # 7. Select the model\n",
    "            if model_name == \"vgg11\":\n",
    "                model = create_vgg11(device=device,class_names=class_names) \n",
    "            elif model_name == \"vgg16\":\n",
    "                model = create_vgg16(device=device,class_names=class_names)\n",
    "            else:\n",
    "                model = create_vgg19(device=device,class_names=class_names) \n",
    "            \n",
    "            # 8. Create a new loss and optimizer for every model\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
    "\n",
    "            # 9. Train target model with target dataloaders and track experiments\n",
    "            engine.train(model=model,\n",
    "                  train_dataloader=dataloaders[0],\n",
    "                  test_dataloader=dataloaders[1], \n",
    "                  val_dataloader=dataloaders[2],\n",
    "                  optimizer=optimizer,\n",
    "                  loss_fn=loss_fn,\n",
    "                  epochs=epochs,\n",
    "                  device=device,\n",
    "                  writer=create_writer(experiment_name=dataloader_name,\n",
    "                                       model_name=model_name,\n",
    "                                       extra=f\"{epochs}_epochs\"))\n",
    "            \n",
    "            # 10. Save the model to file so we can get back the best model\n",
    "            save_filepath = f\"{model_name}_{dataloader_name}_{epochs}_epochs.pth\"\n",
    "            save_model(model=model,\n",
    "                       target_dir=\"models\",\n",
    "                       model_name=save_filepath)\n",
    "            print(\"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
